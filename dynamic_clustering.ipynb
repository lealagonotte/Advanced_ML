{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ab0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dfa396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data\n",
    "movies = pd.read_csv(\n",
    "    \"ml-1m/ml-1m/movies.dat\", sep=\"::\", header=None, engine=\"python\",\n",
    "    encoding=\"ISO-8859-1\", names=[\"MovieID\", \"Title\", \"Genres\"]\n",
    ")\n",
    "users = pd.read_csv(\n",
    "    \"ml-1m/ml-1m/users.dat\", sep=\"::\", header=None, engine=\"python\",\n",
    "    names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"]\n",
    ")\n",
    "ratings = pd.read_csv(\n",
    "    \"ml-1m/ml-1m/ratings.dat\", sep=\"::\", header=None, engine=\"python\",\n",
    "    names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "# Reward in [0,1]\n",
    "ratings[\"reward\"] = (ratings[\"Rating\"] - 1) / 4.0\n",
    "\n",
    "# Unique IDs\n",
    "user_ids = ratings[\"UserID\"].unique()\n",
    "movie_ids = ratings[\"MovieID\"].unique()\n",
    "u2i = {u: i for i, u in enumerate(user_ids)}\n",
    "m2i = {m: i for i, m in enumerate(movie_ids)}\n",
    "i2m = {i: m for m, i in m2i.items()}\n",
    "\n",
    "ratings[\"u_idx\"] = ratings[\"UserID\"].map(u2i)\n",
    "ratings[\"m_idx\"] = ratings[\"MovieID\"].map(m2i)\n",
    "\n",
    "n_users = len(user_ids)\n",
    "n_items = len(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# à comprendre\n",
    "\n",
    "\n",
    "# --- Matrice sparse user-item (valeurs = reward) ---\n",
    "R = sparse.coo_matrix(\n",
    "    (ratings[\"reward\"].values, (ratings[\"u_idx\"].values, ratings[\"m_idx\"].values)),\n",
    "    shape=(n_users, n_items)\n",
    ").tocsr()\n",
    "\n",
    "# --- Features item via SVD ---\n",
    "d = 30  # dimension latente (à tuner)\n",
    "svd = TruncatedSVD(n_components=d, random_state=0)\n",
    "item_factors = svd.fit_transform(R.T)  # (n_items, d)\n",
    "\n",
    "# Normalisation (souvent utile en LinUCB)\n",
    "item_factors = item_factors / (np.linalg.norm(item_factors, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# --- Partition \"dynamique\" des items : clusters (super-bras) ---\n",
    "K = 50  # nb de clusters items = nb de \"bras\"\n",
    "kmeans = KMeans(n_clusters=K, random_state=0, n_init=\"auto\")\n",
    "item_cluster = kmeans.fit_predict(item_factors)\n",
    "\n",
    "cluster_items = {c: np.where(item_cluster == c)[0] for c in range(K)}\n",
    "cluster_centroids = kmeans.cluster_centers_\n",
    "cluster_centroids = cluster_centroids / (np.linalg.norm(cluster_centroids, axis=1, keepdims=True) + 1e-12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627106ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DC3MABLike:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        item_factors: np.ndarray,\n",
    "        item_cluster: np.ndarray,\n",
    "        cluster_items: dict,\n",
    "        alpha: float = 0.6,      # exploration LinUCB\n",
    "        lam: float = 1.0,        # regularisation ridge\n",
    "        edge_init: str = \"kmeans\",  # \"full\" (cher) ou \"kmeans\"\n",
    "        user_init_clusters: int = 30,\n",
    "        split_beta: float = 1.0,  # agressivité de séparation des clusters users\n",
    "        seed: int = 0\n",
    "    ):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.n_users = n_users\n",
    "        self.X = item_factors\n",
    "        self.d = item_factors.shape[1]\n",
    "\n",
    "        self.item_cluster = item_cluster\n",
    "        self.cluster_items = cluster_items\n",
    "        self.K = len(cluster_items)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.lam = lam\n",
    "        self.split_beta = split_beta\n",
    "\n",
    "        # --- Per-user LinUCB stats ---\n",
    "        self.A = np.array([np.eye(self.d) * lam for _ in range(n_users)])  # (n_users, d, d)\n",
    "        self.b = np.zeros((n_users, self.d))\n",
    "        self.t = np.zeros(n_users, dtype=int)  # nb d'updates par user\n",
    "\n",
    "        # --- Graphe utilisateurs (adjacency list) ---\n",
    "        self.G = [set() for _ in range(n_users)]\n",
    "        self._init_graph(edge_init=edge_init, user_init_clusters=user_init_clusters)\n",
    "\n",
    "    def _init_graph(self, edge_init: str, user_init_clusters: int):\n",
    "        if edge_init == \"full\":\n",
    "            for u in range(self.n_users):\n",
    "                self.G[u] = set(range(self.n_users)) - {u}\n",
    "            return\n",
    "\n",
    "        # init plus scalable: cluster users sur leur facteur latent (SVD côté users)\n",
    "        # user factors approx: R * V (ici R * components_.T)\n",
    "        # => on reconstruit vite un embedding users depuis item_factors\n",
    "        # NOTE: si tu veux mieux, calcule explicitement un SVD user-side.\n",
    "        # Ici: user_emb = R @ item_factors (proj)\n",
    "        # (à passer en param si tu préfères)\n",
    "        # fallback: random partition si trop lourd\n",
    "        try:\n",
    "            # approx user embedding: moyenne pondérée des items\n",
    "            # simple et rapide\n",
    "            user_emb = np.zeros((self.n_users, self.d))\n",
    "            # (si R est accessible, tu peux l’injecter via une closure; sinon, random)\n",
    "            # => on fait random ici pour rester autonome\n",
    "            user_emb = self.rng.normal(size=(self.n_users, self.d))\n",
    "            km = KMeans(n_clusters=user_init_clusters, random_state=0, n_init=\"auto\")\n",
    "            ucl = km.fit_predict(user_emb)\n",
    "        except Exception:\n",
    "            ucl = self.rng.integers(0, user_init_clusters, size=self.n_users)\n",
    "\n",
    "        groups = defaultdict(list)\n",
    "        for u, c in enumerate(ucl):\n",
    "            groups[c].append(u)\n",
    "\n",
    "        for _, us in groups.items():\n",
    "            s = set(us)\n",
    "            for u in us:\n",
    "                self.G[u] = s - {u}\n",
    "\n",
    "    def _theta_user(self, u: int) -> np.ndarray:\n",
    "        Ainv = np.linalg.inv(self.A[u])\n",
    "        return Ainv @ self.b[u]\n",
    "\n",
    "    def _cluster_of(self, u: int):\n",
    "        # BFS composante connexe\n",
    "        seen = set([u])\n",
    "        q = deque([u])\n",
    "        while q:\n",
    "            x = q.popleft()\n",
    "            for y in self.G[x]:\n",
    "                if y not in seen:\n",
    "                    seen.add(y)\n",
    "                    q.append(y)\n",
    "        return list(seen)\n",
    "\n",
    "    def _cluster_model(self, cluster_users):\n",
    "        A_sum = np.eye(self.d) * 0.0\n",
    "        b_sum = np.zeros(self.d)\n",
    "        for v in cluster_users:\n",
    "            A_sum += self.A[v]\n",
    "            b_sum += self.b[v]\n",
    "        Ainv = np.linalg.inv(A_sum + 1e-12*np.eye(self.d))\n",
    "        theta = Ainv @ b_sum\n",
    "        return theta, Ainv\n",
    "\n",
    "    def recommend(self, u: int, L: int = 10, per_cluster: int = 2, candidate_clusters: int = 10):\n",
    "        \"\"\"\n",
    "        Recommande une liste de L items.\n",
    "        Stratégie:\n",
    "        - score UCB sur les centroides de clusters items -> top candidate_clusters\n",
    "        - puis à l’intérieur: pick per_cluster meilleurs items par UCB\n",
    "        \"\"\"\n",
    "        cu = self._cluster_of(u)\n",
    "        theta_c, Ainv_c = self._cluster_model(cu)\n",
    "\n",
    "        # UCB sur centroides => choisir des \"super-bras\"\n",
    "        cent = np.array([self.X[self.cluster_items[k]].mean(axis=0) for k in range(self.K)])\n",
    "        cent = cent / (np.linalg.norm(cent, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "        mu = cent @ theta_c\n",
    "        unc = np.sqrt(np.einsum(\"ij,jk,ik->i\", cent, Ainv_c, cent))\n",
    "        ucb = mu + self.alpha * unc\n",
    "\n",
    "        topK = np.argsort(-ucb)[:candidate_clusters]\n",
    "\n",
    "        recs = []\n",
    "        for k in topK:\n",
    "            items = self.cluster_items[k]\n",
    "            if len(items) == 0:\n",
    "                continue\n",
    "\n",
    "            Xk = self.X[items]\n",
    "            mu_i = Xk @ theta_c\n",
    "            unc_i = np.sqrt(np.einsum(\"ij,jk,ik->i\", Xk, Ainv_c, Xk))\n",
    "            ucb_i = mu_i + self.alpha * unc_i\n",
    "\n",
    "            best = items[np.argsort(-ucb_i)[:per_cluster]]\n",
    "            for it in best:\n",
    "                recs.append(int(it))\n",
    "                if len(recs) >= L:\n",
    "                    return recs[:L]\n",
    "\n",
    "        # fallback si pas assez\n",
    "        if len(recs) < L:\n",
    "            fill = self.rng.choice(self.X.shape[0], size=L-len(recs), replace=False).tolist()\n",
    "            recs.extend(fill)\n",
    "        return recs[:L]\n",
    "\n",
    "    def update(self, u: int, item: int, reward: float):\n",
    "        x = self.X[item]\n",
    "        self.A[u] += np.outer(x, x)\n",
    "        self.b[u] += reward * x\n",
    "        self.t[u] += 1\n",
    "\n",
    "        # --- Dynamic user clustering: couper des edges si trop différent ---\n",
    "        # Heuristique CLUB-like: compare theta_u vs theta_v + incertitudes\n",
    "        theta_u = self._theta_user(u)\n",
    "\n",
    "        # incertitude (simple): radius décroît ~ 1/sqrt(t)\n",
    "        rad_u = self.split_beta / np.sqrt(max(self.t[u], 1))\n",
    "\n",
    "        to_remove = []\n",
    "        for v in list(self.G[u]):\n",
    "            theta_v = self._theta_user(v)\n",
    "            rad_v = self.split_beta / np.sqrt(max(self.t[v], 1))\n",
    "            if np.linalg.norm(theta_u - theta_v) > (rad_u + rad_v):\n",
    "                to_remove.append(v)\n",
    "\n",
    "        for v in to_remove:\n",
    "            self.G[u].discard(v)\n",
    "            self.G[v].discard(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ed0837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=20000  hit@10=0.0001  cum_reward=0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m cum_reward += obs_r\n\u001b[32m     27\u001b[39m hits += \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mint\u001b[39m(true_item) \u001b[38;5;129;01min\u001b[39;00m recs)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mbandit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrue_item\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t % \u001b[32m20000\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  hit@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhits/t\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  cum_reward=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcum_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 155\u001b[39m, in \u001b[36mDC3MABLike.update\u001b[39m\u001b[34m(self, u, item, reward)\u001b[39m\n\u001b[32m    153\u001b[39m to_remove = []\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.G[u]):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     theta_v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theta_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m     rad_v = \u001b[38;5;28mself\u001b[39m.split_beta / np.sqrt(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m.t[v], \u001b[32m1\u001b[39m))\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.linalg.norm(theta_u - theta_v) > (rad_u + rad_v):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mDC3MABLike._theta_user\u001b[39m\u001b[34m(self, u)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_theta_user\u001b[39m(\u001b[38;5;28mself\u001b[39m, u: \u001b[38;5;28mint\u001b[39m) -> np.ndarray:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     Ainv = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Ainv @ \u001b[38;5;28mself\u001b[39m.b[u]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mathi\\OneDrive\\Documents\\Mathis\\ENSAE\\3e_annee\\Advance_ML\\Advanced_ML\\Advanced_ML\\venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:669\u001b[39m, in \u001b[36minv\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    666\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    668\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     ainv = \u001b[43m_umath_linalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Trier par temps\n",
    "events = ratings.sort_values(\"Timestamp\")[[\"u_idx\",\"m_idx\",\"reward\"]].to_numpy()\n",
    "\n",
    "bandit = DC3MABLike(\n",
    "    n_users=n_users,\n",
    "    item_factors=item_factors,\n",
    "    item_cluster=item_cluster,\n",
    "    cluster_items=cluster_items,\n",
    "    alpha=0.6,\n",
    "    lam=1.0,\n",
    "    edge_init=\"kmeans\",\n",
    "    user_init_clusters=30,\n",
    "    split_beta=1.2,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "L = 10\n",
    "cum_reward = 0.0\n",
    "hits = 0\n",
    "T = 200_000  # pour aller vite au début (1M events sinon long)\n",
    "\n",
    "for t, (u, true_item, r) in enumerate(events[:T], start=1):\n",
    "    recs = bandit.recommend(int(u), L=L, per_cluster=2, candidate_clusters=10)\n",
    "\n",
    "    obs_r = float(r) if int(true_item) in recs else 0.0\n",
    "    cum_reward += obs_r\n",
    "    hits += int(int(true_item) in recs)\n",
    "\n",
    "    bandit.update(int(u), int(true_item), obs_r)\n",
    "\n",
    "    if t % 20000 == 0:\n",
    "        print(f\"t={t}  hit@{L}={hits/t:.4f}  cum_reward={cum_reward:.1f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
